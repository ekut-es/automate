name: Jetson AGX Xavier
id: jetsonagx
description: An NVIDIA Jetson AGX Xavier Board running Linux

doc:
  -
    title: Technical Reference Manual
    url: doc/Xavier_TRM_DP09253002.pdf
  -
    title: Users Guide
    url: doc/jetson_agx_xavier_developer_kit_user_guide.pdf
  -
    title: WikiChip
    url: https://en.wikichip.org/wiki/nvidia/tegra/xavier
  -
    title: Thermal Design Guide
    url: doc/Jetson_AGX_Xavier_Thermal_Design_Guide_v1.0.pdf


gateway:
  host: tichy.informatik.uni-tuebingen.de
  username: esdata
  lockdir: /local/data/esdata/locks
  
  
connections:
  -
    name: SSH ES
    type: ssh
    host: 192.168.55.1
    username: es
    password: es   # Should we just allow public-keys
    rundir: /home/es/run
        
cores:
  -
    id: 0
    isa: armv8.2-a
    uarch: carmel
    isolated: false
  -
    id: 1
    isa: armv8.2-a
    uarch: carmel
    isolated: false
  -
    id: 2
    isa: armv8.2-a
    uarch: carmel
    isolated: false
  -
    id: 3
    isa: armv8.2-a
    uarch: carmel
    isolated: false
  -
    id: 4
    isa: armv8.2-a
    uarch: carmel
    isolated: false
  -
    id: 5
    isa: armv8.2-a
    uarch: carmel
    isolated: false
  -
    id: 6
    isa: armv8.2-a
    uarch: carmel
    isolated: false
  -
    id: 7
    isa: armv8.2-a
    uarch: carmel
    isolated: false

power_states:
  -
    name: max-freq
    description: "All cores and gpu in maximum frequency CPUs 2.2GHz GPU: 1.377 GHz no DVFS"
    commands:
      - sudo nvpmodel -m 0
      - sudo jetson_clocks
    default: true
        
  -
    name: max-n
    description: "All cores and gpu allowed to run with maximum frequency, CPUs: 1.2-2.2GHz GPU:0.32-1.377 GHz, DVFS enabled"
    commands:
      - echo 77 | sudo tee /sys/devices/pwm-fan/target_pwm
      - sudo nvpmodel -m 0

  -
    name: 30w_all
    description: "All cores and gpu allowed to run with maximum power consumption of 30W CPUs: 1.2-1.2GHz GPU:0.32-1.377 GHz, DVFS enabled"
    commands:
      - echo 77 | sudo tee /sys/devices/pwm-fan/target_pwm
      - sudo nvpmodel -m 3
    idle: true

  -
    name: 30w_fixed
    description: "All cores and gpu allowed to run with maximum power consumption of 30W CPUs: 1.2GHz GPU: 1.377 GHz, no DVFS "
    commands:
      - sudo nvpmodel -m 3
      - sudo jetson_clocks  

os:
  os: linux
  machine: aarch64
  environment: gnu
  distribution: ubuntu
  release: "18.04"
  description: "Ubuntu 18.04.2 LTS"
  kernel: "4.9.140-tegra"             #uname -r
  # Has been disabled for now
  #commandline_extra: "isolcpus=1,2,3,4,5,6,7"
  kernel_config: kernel/config
  kernel_source:
    url: git://nv-tegra.nvidia.com/linux-4.9.git
    tag: tegra-l4t-r32.2.0
  packages: packages.txt
  device_tree: kernel/device_tree.dts
  sysroot: /local/data/buildroots/jetsonagx
  multiarch: True

accelerators:
  -
    name: "gpu"
    description: "The Volta architecture based GPU on Xavier SOCs"
    vendor: nvidia
    type: gpu
    apis:
      -
        name: OpenCL
        version: 1.2
        vendor: nvidia
        platform_id: 0
        device_id: 1
        description : "POCL (Portable OpenCL) implementation of OpenCL for CUDA and ARM"
        includedirs: ["/usr/local/include"]
        libs: ["/usr/local/lib/libOpenCL.so", "-lm"]

      -
        name: CUDA
        version: 10.0
        vendor: nvidia
        basedir: /usr/local/cuda-10.0/
      -
        name: TensorRT
        version: 5.0
        vendor: nvidia
        includedirs: ["/usr/local/cuda-10.0/include"]
        libdirs: ["/usr/local/cuda/lib64"]
        libs: ["-lnvinfer", "-lnvparsers", "-lnvinfer_plugin", "-lnvonnxparser",
               "-lcudnn", "-lcublas", "-lcudart", "-lrt", "-ldl", "-lpthread"]

  -
    name: "nvdla_1"
    description: "Nvidia Deep Learning Accelerator"
    vendor: nvidia
    type: ai
    apis:
      -
        name: TensorRT
        version: 5.0
        vendor: nvidia
        base_dir: ["/usr/local/cuda-10.0"]
        includedirs: ["/usr/local/cuda-10.0/include"]
        libdirs: ["/usr/local/cuda-10.0/lib64"]
        libs: ["-lnvinfer", "-lnvparsers", "-lnvinfer_plugin", "-lnvonnxparser",
               "-lcudnn", "-lcublas", "-lcudart", "-lrt", "-ldl", "-lpthread"]

  -
    name: "nvdla_2"
    description: "Nvidia Deep Learning Accelerator"
    vendor: nvidia
    type: ai
    apis:
      -
        name: TensorRT
        version: 5.0
        vendor: nvidia
        includedirs: ["/usr/local/cuda-10.0/include"]
        libdirs: ["/usr/local/cuda/lib64"]
        libs: ["-lnvinfer", "-lnvparsers", "-lnvinfer_plugin", "-lnvonnxparser",
               "-lcudnn", "-lcublas", "-lcudart", "-lrt", "-ldl", "-lpthread"]

  -
    name: "pva_1"
    description: "NVIDIA programmable vision accelerator"
    vendor: nvidia
  -
    name: "pva_2"
    description: "NVIDIA programmable vision accelerator"
    vendor: nvidia
  -
    name: "sofe"
    description: "Stereo and Optical Flow Engine"
    vendor: nvidia
  -
    name: "vic"
    description: "Video Image Compositor"
    vendor: nvidia
  -
    name: "ape"
    description: "Audio Processing Engine based on Cortex-A9"
    vendor: nvidia
